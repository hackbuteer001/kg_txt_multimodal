{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 12 03:54:28 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:05.0 Off |                  Off |\n",
      "| N/A   54C    P0   189W / 300W |  26702MiB / 32480MiB |     91%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:06.0 Off |                  Off |\n",
      "| N/A   34C    P0    65W / 300W |   5299MiB / 32480MiB |     10%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     39750      C   python                                     24565MiB |\n",
      "|    0     79488      C   ...buntu/anaconda3/envs/kg_text/bin/python  2127MiB |\n",
      "|    1    105425      C   python                                      5289MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "\n",
    "# Paths\n",
    "EXP_PATH = '/home/ubuntu/lxmert/' #os.getcwd() \n",
    "SRC_PATH = os.path.join(EXP_PATH, 'src/run_pretraining.py')\n",
    "TASK_NAME = 'masked_literal_prediction'\n",
    "\n",
    "######################\n",
    "RUN_NAME = 'BSS_TEST'\n",
    "######################\n",
    "\n",
    "TRAINING_CONFIG = {\n",
    "    \"model_type\":\"lxmert\",\n",
    "    \"config_name\":os.path.join(EXP_PATH,\"config/config_transe_visual.json\"),\n",
    "    \"tokenizer_name\":\"bert-base-uncased\",\n",
    "    \"do_train\": True,\n",
    "    \"evaluate_during_training\": True,\n",
    "    \"do_eval\": True,\n",
    "    \"prediction_loss_only\":False,\n",
    "    \"overwrite_output_dir\":True,\n",
    "    \"mlm_probability\": 0.15,\n",
    "    \"block_size\": 512,\n",
    "    \"per_device_train_batch_size\": 32,\n",
    "    \"per_device_eval_batch_size\": 8,\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"num_train_epochs\": 50,\n",
    "    \"logging_steps\": int(642/20),\n",
    "    \"save_steps\": int(642/5),\n",
    "    \"eval_steps\": int(642/5),\n",
    "    \"eval_criterion\" :\"lang_acc,kg_acc\",\n",
    "    \"train_data_file\":os.path.join(EXP_PATH,\"data/{}/train\".format(TASK_NAME)),\n",
    "    \"train_data_files\":None, # add\n",
    "    \"eval_data_file\": os.path.join(EXP_PATH,\"data/{}/valid\".format(TASK_NAME)),\n",
    "    #\"test_data_file\": os.path.join(EXP_PATH, \"data/{}/test\".format(TASK_NAME)),\n",
    "    \"run_name\":RUN_NAME,\n",
    "    \"output_dir\":os.path.join(EXP_PATH,\"pretrained_models/{}\".format(RUN_NAME)),\n",
    "    \"cache_dir\":None,\n",
    "    \"model_name_or_path\":None\n",
    "}\n",
    "\n",
    "TRAINING_CONFIG_LIST = list()\n",
    "for (k,v) in list(TRAINING_CONFIG.items()):\n",
    "    if (isinstance(v, bool)):\n",
    "        if v:\n",
    "            TRAINING_CONFIG_LIST.append(\"--{}\".format(k))\n",
    "    else:\n",
    "        TRAINING_CONFIG_LIST.append(\"--{}={}\".format(k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'model_type': 'lxmert',\n",
       "  'config_name': '/home/ubuntu/lxmert/config/config_transe_visual.json',\n",
       "  'tokenizer_name': 'bert-base-uncased',\n",
       "  'do_train': True,\n",
       "  'evaluate_during_training': True,\n",
       "  'do_eval': True,\n",
       "  'prediction_loss_only': False,\n",
       "  'overwrite_output_dir': True,\n",
       "  'mlm_probability': 0.15,\n",
       "  'block_size': 512,\n",
       "  'per_device_train_batch_size': 32,\n",
       "  'per_device_eval_batch_size': 8,\n",
       "  'learning_rate': 0.0005,\n",
       "  'num_train_epochs': 50,\n",
       "  'logging_steps': 32,\n",
       "  'save_steps': 128,\n",
       "  'eval_steps': 128,\n",
       "  'eval_criterion': 'lang_acc,kg_acc',\n",
       "  'train_data_file': '/home/ubuntu/lxmert/data/masked_literal_prediction/train',\n",
       "  'train_data_files': None,\n",
       "  'eval_data_file': '/home/ubuntu/lxmert/data/masked_literal_prediction/valid',\n",
       "  'run_name': 'BSS_TEST',\n",
       "  'output_dir': '/home/ubuntu/lxmert/pretrained_models/BSS_TEST',\n",
       "  'cache_dir': None,\n",
       "  'model_name_or_path': None},\n",
       " ['--model_type=lxmert',\n",
       "  '--config_name=/home/ubuntu/lxmert/config/config_transe_visual.json',\n",
       "  '--tokenizer_name=bert-base-uncased',\n",
       "  '--do_train',\n",
       "  '--evaluate_during_training',\n",
       "  '--do_eval',\n",
       "  '--overwrite_output_dir',\n",
       "  '--mlm_probability=0.15',\n",
       "  '--block_size=512',\n",
       "  '--per_device_train_batch_size=32',\n",
       "  '--per_device_eval_batch_size=8',\n",
       "  '--learning_rate=0.0005',\n",
       "  '--num_train_epochs=50',\n",
       "  '--logging_steps=32',\n",
       "  '--save_steps=128',\n",
       "  '--eval_steps=128',\n",
       "  '--eval_criterion=lang_acc,kg_acc',\n",
       "  '--train_data_file=/home/ubuntu/lxmert/data/masked_literal_prediction/train',\n",
       "  '--train_data_files=None',\n",
       "  '--eval_data_file=/home/ubuntu/lxmert/data/masked_literal_prediction/valid',\n",
       "  '--run_name=BSS_TEST',\n",
       "  '--output_dir=/home/ubuntu/lxmert/pretrained_models/BSS_TEST',\n",
       "  '--cache_dir=None',\n",
       "  '--model_name_or_path=None'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_CONFIG, TRAINING_CONFIG_LIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br/>\n",
    "\n",
    "`run_pretraining.py`\n",
    "\n",
    "<br/>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ubuntu/lxmert/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import LxmertForKGTokPredAndMaskedLM\n",
    "from utils.dataset import get_dataset\n",
    "from utils.data_collator import NodeMasking_DataCollator, NodeClassification_DataCollator, LiteralRegression_DataCollator\n",
    "\n",
    "# From Huggingface transformers package\n",
    "from transformers import (\n",
    "    CONFIG_MAPPING,\n",
    "    MODEL_WITH_LM_HEAD_MAPPING,\n",
    "    LxmertConfig,\n",
    "    LxmertTokenizer,\n",
    "    PreTrainedTokenizer,\n",
    "    # Trainer,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "# from utils.parameters import parser\n",
    "# model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
    "\n",
    "import easydict\n",
    "args = easydict.EasyDict(TRAINING_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/lxmert/config/config_transe_visual.json'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.config_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.config_name:\n",
    "    config = LxmertConfig.from_pretrained(args.config_name, cache_dir=args.cache_dir)\n",
    "# elif model_args.model_name_or_path:\n",
    "#     config = LxmertConfig.from_pretrained(args.model_name_or_path, cache_dir=args.cache_dir)\n",
    "# else:\n",
    "#     config = CONFIG_MAPPING[args.model_type]()\n",
    "#     logger.warning(\"You are instantiating a new config instance from scratch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-base-uncased'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.tokenizer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.tokenizer_name:\n",
    "    tokenizer = LxmertTokenizer.from_pretrained(args.tokenizer_name, cache_dir=args.cache_dir)\n",
    "# elif model_args.model_name_or_path:\n",
    "#     tokenizer = LxmertTokenizer.from_pretrained(args.model_name_or_path, cache_dir=args.cache_dir)\n",
    "# else:\n",
    "#     raise ValueError(\n",
    "#         \"You are instantiating a new tokenizer from scratch. This is not supported, but you can do it from another script, save it,\"\n",
    "#         \"and load it from here, using --tokenizer_name\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if args.model_name_or_path: # False\n",
    "#     model = LxmertForKGTokPredAndMaskedLM.from_pretrained(\n",
    "#         args.model_name_or_path,\n",
    "#         from_tf=bool(\".ckpt\" in args.model_name_or_path), # False\n",
    "#         config=config,\n",
    "#         cache_dir=args.cache_dir, # no cache_dir\n",
    "#     )\n",
    "# else:\n",
    "#     logger.info(\"Training new model from scratch\")\n",
    "model = LxmertForKGTokPredAndMaskedLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get datasets\n",
    "train_dataset = (\n",
    "    get_dataset(args,\n",
    "                tokenizer=tokenizer,\n",
    "                kg_pad=config.kg_special_token_ids[\"PAD\"]) if args.do_train else None\n",
    ")\n",
    "eval_dataset = (\n",
    "    get_dataset(args,\n",
    "                tokenizer=tokenizer,\n",
    "                kg_pad=config.kg_special_token_ids[\"PAD\"], evaluate=True) if args.do_eval else None\n",
    ")\n",
    "# test_dataset = (\n",
    "#     get_dataset(data_args, tokenizer=tokenizer, kg_pad=config.kg_special_token_ids[\"PAD\"], test=True)\n",
    "#     if training_args.do_eval\n",
    "#     else None\n",
    "# )\n",
    "data_collator = NodeClassification_DataCollator(tokenizer=tokenizer,\n",
    "                                                kg_special_token_ids=config.kg_special_token_ids,\n",
    "                                                kg_size = config.vocab_size['kg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.do_train, args.do_eval\n",
    "# config.kg_special_token_ids, config.vocab_size\n",
    "# !wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.training_args import TrainingArguments\n",
    "\n",
    "train_args = TrainingArguments(output_dir='BSS_TEST',\n",
    "    do_train=True,\n",
    "    do_eval=False,\n",
    "    local_rank=-1,\n",
    "    per_device_train_batch_size=1,  \n",
    "    learning_rate=1e-3,\n",
    "    num_train_epochs=1,\n",
    "    eval_criterion='lang_acc,kg_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_args.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 81512<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64fd2f2b3c33417fa57c5ab9680c0ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>wandb/run-20201112_035650-sr4t1j25/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>wandb/run-20201112_035650-sr4t1j25/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">snowy-frost-46</strong>: <a href=\"https://wandb.ai/seongsubae/lxmert/runs/sr4t1j25\" target=\"_blank\">https://wandb.ai/seongsubae/lxmert/runs/sr4t1j25</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.9<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">stellar-spaceship-47</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/seongsubae/lxmert\" target=\"_blank\">https://wandb.ai/seongsubae/lxmert</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/seongsubae/lxmert/runs/2p2f552q\" target=\"_blank\">https://wandb.ai/seongsubae/lxmert/runs/2p2f552q</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20201112_035654-2p2f552q</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trainer import Trainer\n",
    "\n",
    "# Initialize our Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "# if train_args_dict.do_train:\n",
    "model_path = (\n",
    "    train_args_dict.model_name_or_path\n",
    "    if args.model_name_or_path is not None and os.path.isdir(args.model_name_or_path)\n",
    "    else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20534"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_train_data_loader = trainer.get_train_dataloader()\n",
    "trainer.num_examples(temp_train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/lxmert/src/utils/data_collator.py:253: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  probability_matrix.masked_fill_(torch.tensor(entity_mask, dtype=torch.bool), value=0.0)\n",
      "/home/ubuntu/lxmert/src/utils/data_collator.py:254: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label_mask.masked_fill_(torch.tensor(entity_mask, dtype=torch.bool), value=False)\n"
     ]
    }
   ],
   "source": [
    "temp_input_data = next(iter(temp_train_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lang_input_ids', 'kg_input_ids', 'lang_attention_mask', 'kg_attention_mask', 'kg_label', 'token_type_ids', 'kg_label_mask', 'lm_label'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_input_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_input_data['lang_input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 170])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_input_data['kg_input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_input_data['lang_attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_input_data['kg_attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100,  427,  747,  869,\n",
       "         2918, 2646, 2759, 2591, 2877,  986, 1596, 1909, 2789,  200, 1288, 1408,\n",
       "         2168, 2294, 3066, 1267, 2678, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_input_data['kg_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_input_data['kg_label_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 23951,  -100,\n",
       "          -100,  2891,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_input_data['lm_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18.47144317626953,\n",
       " {'lm_loss': 10.283180236816406, 'kg_loss': 8.188261985778809})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.training_step(model, temp_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_output_data = model(**temp_input_data, output_attentions=True, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.output_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'loss_dict', 'lang_prediction_logits', 'kg_prediction_logits', 'cross_relationship_score', 'language_attentions', 'kg_attentions', 'cross_encoder_attentions'])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_output_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp_output_data['cross_encoder_attentions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 512, 170])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_output_data['cross_encoder_attentions'][-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 170])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_output_data['cross_encoder_attentions'][-1][0, 0, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lang_input_ids', 'kg_input_ids', 'lang_attention_mask', 'kg_attention_mask', 'kg_label', 'token_type_ids', 'kg_label_mask', 'lm_label'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_input_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/kg_text/lib/python3.7/site-packages/ipykernel/__main__.py:2: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = temp_input_data['lang_input_ids'].cpu().squeeze()\n",
    "temp_len = len(temp[:temp.nonzero().shape[0]])\n",
    "temp_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2 = temp_input_data['kg_input_ids'].cpu().squeeze()\n",
    "temp2_len = len(temp2[:temp2.nonzero().shape[0]])\n",
    "temp2_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5ae4773610>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 562.286x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "head_idx=0\n",
    "\n",
    "plt.matshow(\n",
    "temp_output_data['cross_encoder_attentions'][-1][0,head_idx,\n",
    "                                                 :temp_len,:temp2_len].cpu().detach().numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 512, 512])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_output_data['language_attentions'][-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_input_data['lang_input_ids'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_kg_text)",
   "language": "python",
   "name": "conda_kg_text"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
