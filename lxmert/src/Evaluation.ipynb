{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Set envs & Load DB, Model and Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import easydict\n",
    "\n",
    "# Set path\n",
    "EXP_PATH = os.path.dirname(os.getcwd())\n",
    "TASK_NAME = 'masked_literal_prediction'\n",
    "RUN_NAME = 'TransE_NoKGenc_H128'\n",
    "\n",
    "# Essential Hyperparameters\n",
    "args = easydict.EasyDict({\n",
    "    \"model_type\":\"lxmert\",\n",
    "    \"model_name_or_path\":os.path.join(EXP_PATH,'pretrained_models',RUN_NAME),\n",
    "    \"tokenizer_name\":\"bert-base-uncased\",\n",
    "    \"cache_dir\":None,\n",
    "    \"eval_criterion\" :\"lang_acc,kg_acc\",\n",
    "    \"block_size\":-1,\n",
    "    \"batch_size\":1,\n",
    "    \"eval_data_file\": os.path.join(EXP_PATH,\"data/{}/valid\".format(TASK_NAME)),\n",
    "    \"test_data_file\": os.path.join(EXP_PATH, \"data/{}/test\".format(TASK_NAME)),\n",
    "    \"run_name\":RUN_NAME,\n",
    "    \"seed\":1234,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base packages\n",
    "import logging\n",
    "import math\n",
    "from dataclasses import dataclass, field\n",
    "from glob import glob\n",
    "from typing import Optional\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
    "\n",
    "# Own implementation\n",
    "from utils.parameters import parser\n",
    "from utils.dataset import get_dataset\n",
    "from utils.data_collator import NodeMasking_DataCollator, NodeClassification_DataCollator, LiteralRegression_DataCollator\n",
    "from model import LxmertForPreTraining, LxmertForKGTokPredAndMaskedLM\n",
    "\n",
    "# From Huggingface transformers package\n",
    "from transformers import (\n",
    "    CONFIG_MAPPING,\n",
    "    MODEL_WITH_LM_HEAD_MAPPING,\n",
    "    LxmertConfig,\n",
    "    LxmertTokenizer,\n",
    "    PreTrainedTokenizer,\n",
    "    # Trainer,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "# Set enviroments\n",
    "set_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LxmertTokenizer.from_pretrained(args.tokenizer_name, cache_dir=args.cache_dir)\n",
    "## Sanity check\n",
    "print(tokenizer.convert_tokens_to_ids(tokenizer.tokenize('Just for sanity check [CLS] [SEP] [MASK] [PAD]')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = LxmertConfig.from_pretrained(args.model_name_or_path, cache_dir=args.cache_dir)\n",
    "\n",
    "\n",
    "# Load trained model\n",
    "model = LxmertForKGTokPredAndMaskedLM.from_pretrained(\n",
    "    args.model_name_or_path,\n",
    "    from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
    "    config=config,\n",
    "    cache_dir=args.cache_dir,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "## Sanity check\n",
    "print('='*100)\n",
    "print(config)\n",
    "print('='*100)\n",
    "print(model)\n",
    "print('='*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Class-wise accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader with masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model on CPU for prediction\n",
    "model.cuda()\n",
    "\n",
    "# Build vocab for grpah\n",
    "id2entity = {int(line.split('\\t')[1])+len(config.kg_special_token_ids):line.split('\\t')[0].split('^^')[0] for line in open(os.path.join(EXP_PATH,'data','entity2id.txt')).read().splitlines()[1:]}\n",
    "label2entity = {v:id2entity[k] for (k,v) in torch.load(os.path.join(EXP_PATH,\"data/{}/id2label\".format(TASK_NAME))).items()}\n",
    "\n",
    "if args.block_size <= 0:\n",
    "    args.block_size = tokenizer.max_len\n",
    "    # Our input block size will be the max possible for the model\n",
    "else:\n",
    "    args.block_size = min(args.block_size, tokenizer.max_len)\n",
    "\n",
    "# Get datasets\n",
    "dataset = (\n",
    "    get_dataset(args, tokenizer=tokenizer, kg_pad=config.kg_special_token_ids[\"PAD\"], evaluate=True)\n",
    ")\n",
    "\n",
    "data_collator = NodeClassification_DataCollator(tokenizer=tokenizer, kg_special_token_ids=config.kg_special_token_ids, kg_size = config.vocab_size['kg'])\n",
    "\n",
    "# Get data loader\n",
    "data_loader = DataLoader(\n",
    "    dataset,\n",
    "    sampler=SequentialSampler(dataset),\n",
    "    batch_size=args.batch_size,\n",
    "    collate_fn=data_collator,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "# Sanity check\n",
    "print(next(iter(data_loader))['lang_input_ids'])\n",
    "print(label2entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric for class-wise accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ClassWise_Accruacy(logit, label, cwa_dict):\n",
    "    _, predicted = torch.max(logit, dim=2)\n",
    "    active_correct = (predicted == label)[~label.eq(-100)].tolist()\n",
    "    active_label = label[~label.eq(-100)].tolist()\n",
    "    for correct, label in zip(active_correct, active_label):\n",
    "        cwa_dict[label].append(correct)\n",
    "    return cwa_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure class-wise accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {'lang_cwa':{k:list() for k in range(config.vocab_size['lang'])},'kg_cwa':{k:list() for k in range(config.num_kg_labels)}}\n",
    "\n",
    "for step, inputs in tqdm(enumerate(data_loader),total=len(data_loader)):\n",
    "    # Load tensors to CUDA devices\n",
    "    for k, v in inputs.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            inputs[k] = v.cuda()\n",
    "            \n",
    "    # Eval per minibatch\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs,return_dict=True)\n",
    "        metrics['lang_cwa'] = get_ClassWise_Accruacy(outputs['lang_prediction_logits'].data, inputs['lm_label'].data,metrics['lang_cwa'])\n",
    "        metrics['kg_cwa'] = get_ClassWise_Accruacy(outputs['kg_prediction_logits'].data, inputs['kg_label'].data,metrics['kg_cwa'])\n",
    "\n",
    "for k in metrics:\n",
    "    if 'lang' in k:\n",
    "        metrics[k] = dict([(tokenizer.convert_ids_to_tokens(label),sum(correct)/len(correct)) for label, correct in list(metrics[k].items()) if len(correct)>0])\n",
    "    else:\n",
    "        metrics[k] = dict([(label2entity[label],sum(correct)/len(correct)) for label, correct in list(metrics[k].items()) if len(correct)>0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot class-wise accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 0.25\n",
    "modality = 'kg'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "failure_case = {k:v for k,v in metrics['{}_cwa'.format(modality)].items() if v<P}\n",
    "\n",
    "print(\"# {} label under {} : [{}]\\n\".format(modality,P,len(failure_case)))\n",
    "print(failure_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize attention score per head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load visualization tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "require.config({\n",
    "  paths: {\n",
    "      d3: '//cdnjs.cloudflare.com/ajax/libs/d3/3.4.8/d3.min',\n",
    "      jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
    "  }\n",
    "});\n",
    "\n",
    "from bertviz import head_view\n",
    "\n",
    "def show_head_view(data_info, view_option='language'):\n",
    "        \n",
    "    lang_tokens = data_info['lang_tokens']\n",
    "    kg_tokens = data_info['kg_tokens']\n",
    "    lang_attentions = data_info['lang_attentions']\n",
    "    cross_attentions = data_info['cross_attentions']\n",
    "    \n",
    "    print(data_info['lang_seq'])\n",
    "    \n",
    "    if view_option == 'langauge':\n",
    "        head_view(attention=lang_attentions, tokens=lang_tokens)\n",
    "        \n",
    "    else:\n",
    "        all_tokens = lang_tokens + kg_tokens\n",
    "        sentence_b_start = len(lang_tokens)\n",
    "        head_view(attention=cross_attentions, tokens=all_tokens , sentence_b_start=sentence_b_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader without masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model on CPU for prediction\n",
    "model.cpu()\n",
    "\n",
    "if args.block_size <= 0:\n",
    "    args.block_size = tokenizer.max_len\n",
    "    # Our input block size will be the max possible for the model\n",
    "else:\n",
    "    args.block_size = min(args.block_size, tokenizer.max_len)\n",
    "\n",
    "# Get datasets\n",
    "dataset = (\n",
    "    get_dataset(args, tokenizer=tokenizer, kg_pad=config.kg_special_token_ids[\"PAD\"], evaluate=True)\n",
    ")\n",
    "\n",
    "data_collator = NodeClassification_DataCollator(tokenizer=tokenizer, kg_special_token_ids=config.kg_special_token_ids, kg_size = config.vocab_size['kg'],prediction=True)\n",
    "\n",
    "# Get data loader\n",
    "data_loader = DataLoader(\n",
    "    dataset,\n",
    "    sampler=SequentialSampler(dataset),\n",
    "    batch_size=args.batch_size,\n",
    "    collate_fn=data_collator,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get attention score from sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2entity = {int(line.split('\\t')[1])+len(config.kg_special_token_ids):\\\n",
    "             line.split('\\t')[0].split('^^')[0] for line in open(os.path.join(EXP_PATH,'data','entity2id.txt')).read().splitlines()[1:]}\n",
    "\n",
    "\n",
    "def get_data_info_from_sample_for_viz(sample_idx=0,\n",
    "                                      model=model,\n",
    "                                      data_loader=data_loader,\n",
    "                                      tokenizer=tokenizer,\n",
    "                                      kg_id_mapping=id2entity):\n",
    "    \n",
    "    for idx, data in enumerate(data_loader):\n",
    "        if idx==sample_idx:\n",
    "            input_data = data\n",
    "            break\n",
    "    \n",
    "    data_info = {}\n",
    "    \n",
    "    # lang part\n",
    "    lang_temp_input_ids = input_data['lang_input_ids'].cpu().squeeze()\n",
    "    lang_input_len = len(lang_temp_input_ids.nonzero())\n",
    "    lang_tokens = tokenizer.convert_ids_to_tokens(lang_temp_input_ids[:lang_input_len])\n",
    "    lang_seq = tokenizer.convert_tokens_to_string(\n",
    "        tokenizer.convert_ids_to_tokens(lang_temp_input_ids[:lang_input_len]))\n",
    "    data_info['lang_input_len'] = lang_input_len \n",
    "    data_info['lang_tokens'] = lang_tokens\n",
    "    data_info['lang_seq'] = lang_seq\n",
    "    \n",
    "    # kg part\n",
    "    kg_temp_input_ids = input_data['kg_input_ids'].cpu().squeeze()\n",
    "    kg_input_len = len(kg_temp_input_ids.nonzero())\n",
    "    kg_tokens = list(map(lambda x: kg_id_mapping[x], kg_temp_input_ids[:kg_input_len].tolist()))\n",
    "    data_info['kg_input_len'] = kg_input_len\n",
    "    data_info['kg_tokens'] = kg_tokens\n",
    "    \n",
    "    # output attentions\n",
    "    output_data = model(**input_data, output_attentions=True, return_dict=True)\n",
    "    data_info['lang_attentions'] =  [l_layer[:,:,\n",
    "                                             :lang_input_len,\n",
    "                                             :lang_input_len].cpu() for l_layer in output_data['language_attentions']]\n",
    "    temp_c_attentions = torch.cat([c_layer[:,:,\n",
    "                                          :(lang_input_len+kg_input_len),\n",
    "                                          :(kg_input_len+lang_input_len)].cpu() for c_layer in output_data['cross_encoder_attentions']])\n",
    "    temp_c1_attentions = temp_c_attentions[:,:,:,:kg_input_len]\n",
    "    temp_c2_attentions = temp_c_attentions[:,:,:,-lang_input_len:]\n",
    "    c_attentions = torch.cat([temp_c2_attentions, temp_c1_attentions], dim=-1)\n",
    "    data_info['cross_attentions'] = [c_attentions[layer_idx,:,:,:].unsqueeze(0) for layer_idx in range(len(temp_c_attentions[:]))]\n",
    "    \n",
    "    return data_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_data_info_from_sample_for_viz(sample_idx=26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_head_view(result, 'cross')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_head_view(result, 'langauge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:skyblue\">Supp 1. Visualize attention score in matrix form</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader without masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model on CPU for prediction\n",
    "model.cpu()\n",
    "\n",
    "if args.block_size <= 0:\n",
    "    args.block_size = tokenizer.max_len\n",
    "    # Our input block size will be the max possible for the model\n",
    "else:\n",
    "    args.block_size = min(args.block_size, tokenizer.max_len)\n",
    "\n",
    "# Get datasets\n",
    "dataset = (\n",
    "    get_dataset(args, tokenizer=tokenizer, kg_pad=config.kg_special_token_ids[\"PAD\"], evaluate=True)\n",
    ")\n",
    "\n",
    "data_collator = NodeClassification_DataCollator(tokenizer=tokenizer, kg_special_token_ids=config.kg_special_token_ids, kg_size = config.vocab_size['kg'],prediction=True)\n",
    "\n",
    "# Get data loader\n",
    "data_loader = DataLoader(\n",
    "    dataset,\n",
    "    sampler=SequentialSampler(dataset),\n",
    "    batch_size=args.batch_size,\n",
    "    collate_fn=data_collator,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get attention score from sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SAMPLE_IDX = 26\n",
    "\n",
    "id2entity = {int(line.split('\\t')[1])+len(config.kg_special_token_ids):line.split('\\t')[0].split('^^')[0] for line in open(os.path.join(EXP_PATH,'data','entity2id.txt')).read().splitlines()[1:]}\n",
    "for idx, data in enumerate(data_loader):\n",
    "    if idx==SAMPLE_IDX:\n",
    "        input_data = data\n",
    "        break\n",
    "        \n",
    "print('==== Text ====')\n",
    "temp = input_data['lang_input_ids'].cpu().squeeze()\n",
    "lang_tokens = tokenizer.convert_ids_to_tokens(temp[:temp.nonzero().shape[0]].tolist())\n",
    "print('Token seq : {}\\n'.format(lang_tokens))\n",
    "print('Full sentence : {}\\n\\n'.format(tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(temp[:temp.nonzero().shape[0]].tolist()))))\n",
    "\n",
    "print('==== KG ====')\n",
    "temp = input_data['kg_input_ids'].cpu().squeeze()\n",
    "kg_tokens = list(map(lambda x: id2entity[x],temp[:temp.nonzero().shape[0]].tolist()))\n",
    "print('Token seq : {}\\n'.format(kg_tokens))\n",
    "\n",
    "output_data = model(**input_data, output_attentions=True, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross modal attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(model.config.x_layers, model.config.num_attention_heads, figsize=(20,20))\n",
    "for layer_idx in range(model.config.x_layers):\n",
    "    for head_idx in range(model.config.num_attention_heads):\n",
    "        axs[model.config.l_layers-1-layer_idx, head_idx].matshow(\n",
    "            output_data['cross_encoder_attentions'][layer_idx][0,head_idx,\n",
    "                                                         :len(lang_tokens),:len(kg_tokens)].cpu().detach().numpy(),\n",
    "            #cmap='gray',\n",
    "        )\n",
    "        #if (layer_idx == config.x_layers-1) and (head_idx==):\n",
    "        if (layer_idx == 0) and (head_idx==0):\n",
    "            axs[layer_idx, head_idx].set_xticklabels(kg_tokens, rotation='45',horizontalalignment='left', fontsize=8)\n",
    "            axs[layer_idx, head_idx].set_yticklabels(lang_tokens, rotation='45',horizontalalignment='right', fontsize=8)\n",
    "            axs[layer_idx, head_idx].set_xticks(range(len(kg_tokens)))\n",
    "            axs[layer_idx, head_idx].set_yticks([range(len(lang_tokens))])\n",
    "        axs[0, head_idx].set_title(\"Head_{}\\n\".format(head_idx+1))\n",
    "    axs[layer_idx, 0].set_ylabel('Layer_{}\\n'.format(model.config.l_layers-layer_idx))\n",
    "plt.suptitle('Cross Modal Attention Vis', fontsize=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(model.config.l_layers, model.config.num_attention_heads, figsize=(18,20))\n",
    "for layer_idx in range(model.config.l_layers):\n",
    "    for head_idx in range(model.config.num_attention_heads):\n",
    "        axs[model.config.l_layers-1-layer_idx, head_idx].matshow(\n",
    "            output_data['language_attentions'][layer_idx][0,head_idx,\n",
    "                                                          :len(lang_tokens),\n",
    "                                                          :len(lang_tokens)].cpu().detach().numpy(),\n",
    "            #cmap='gray',\n",
    "        )\n",
    "        if (layer_idx == 0) and (head_idx==0):\n",
    "            axs[layer_idx, head_idx].set_xticks(range(len(lang_tokens)))\n",
    "            axs[layer_idx, head_idx].set_yticks(range(len(lang_tokens)))\n",
    "            axs[layer_idx, head_idx].set_xticklabels(lang_tokens, rotation='45',horizontalalignment='left', fontsize=8)\n",
    "            axs[layer_idx, head_idx].set_yticklabels(lang_tokens, rotation='45',horizontalalignment='right', fontsize=8)\n",
    "        axs[0, head_idx].set_title(\"Head_{}\\n\".format(head_idx+1))\n",
    "    axs[layer_idx, 0].set_ylabel('Layer_{}\\n'.format(model.config.l_layers-layer_idx))\n",
    "plt.suptitle('Language Attention Vis', fontsize=40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_exp)",
   "language": "python",
   "name": "conda_exp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
