diff --git a/gtx/Run_configs.py b/gtx/Run_configs.py
index d9e37bc..93ef274 100644
--- a/gtx/Run_configs.py
+++ b/gtx/Run_configs.py
@@ -60,9 +60,9 @@ class Configuration():
             "use_tpu" : config['use_tpu'],
             "dataloader_pin_memory" : False if not config['use_tpu'] else True,
             "label_domain" : config['label_domain'],
-            "train_data_file":os.path.join(self.EXP_PATH,f"data/{'knowmix/' if config['KnowMix'] else ''}{self.DB}_{self.DB_size}/{self.MODEL_NAME}/train"),
-            "eval_data_file": os.path.join(self.EXP_PATH,f"data/{'knowmix/' if config['KnowMix'] else ''}{self.DB}_{self.DB_size}/{self.MODEL_NAME}/valid"),
-            "test_data_file": os.path.join(self.EXP_PATH,f"data/{'knowmix/' if config['KnowMix'] else ''}{self.DB}_{self.DB_size}/{self.MODEL_NAME}/test"),
+            "train_data_file":os.path.join('/home/sjpark/experiments/lightning_base/kg_txt_multimodal/gtx',f"fixed_data/{'knowmix/' if config['KnowMix'] else ''}{self.DB}_{self.DB_size}/{self.MODEL_NAME}/train"),
+            "eval_data_file": os.path.join('/home/sjpark/experiments/lightning_base/kg_txt_multimodal/gtx',f"fixed_data/{'knowmix/' if config['KnowMix'] else ''}{self.DB}_{self.DB_size}/{self.MODEL_NAME}/valid"),
+            "test_data_file": os.path.join('/home/sjpark/experiments/lightning_base/kg_txt_multimodal/gtx',f"fixed_data/{'knowmix/' if config['KnowMix'] else ''}{self.DB}_{self.DB_size}/{self.MODEL_NAME}/test"),
             "run_name":f"{self.TASK_NAME}_{self.RUN_NAME}"
         }
 
diff --git a/gtx/run.py b/gtx/run.py
index 684768e..03fe6c1 100644
--- a/gtx/run.py
+++ b/gtx/run.py
@@ -6,7 +6,7 @@ import itertools
 from Run_configs import Configuration
 
 # GPU setting
-os.environ["CUDA_VISIBLE_DEVICES"] = '5'
+os.environ["CUDA_VISIBLE_DEVICES"] = '0'
 
 # TPU setting
 TPU = False
@@ -15,13 +15,13 @@ for preset in [
     # {'model':'cross','architecture':'both','knowmix':'init','scratch':False},
     # {'model':'cross','architecture':'both','knowmix':'init,adm','scratch':False},
     # {'db':'dx,prx','model':'transe','architecture':'lm ','knowmix':'','scratch':False},
-    {'db':'dx,prx','model':'cross','architecture':'both','knowmix':'init,abs','scratch':False},
-    {'db':'px','model':'cross','architecture':'both','knowmix':'init,abs','scratch':False},
+    {'db':'dx,prx','model':'cross','architecture':'kg','knowmix':'','scratch':False},
+    # {'db':'px','model':'cross','architecture':'both','knowmix':'init,abs','scratch':False},
 ]:
-    for _task in [0,1,2,3,4,5,7]:
+    for _task in [0]: # [5, 7]
         if (_task==3) and (preset['db']=='px'):
             continue
-        for _SEED in [1234,123,12,1,42]: # , 123, 12, 1, 42]: # , 1, 42]:
+        for _SEED in [1234]: # , 123, 12, 1, 42]: # , 1, 42]:
             if (_task==0) and (_SEED!=1234):
                 continue
             config = {
@@ -37,7 +37,7 @@ for preset in [
                 # architecture : both / kg / lm / rand
                 'architecture' : preset['architecture'],
                 # label domain : graph / text
-                'label_domain' : 'text',
+                'label_domain' : 'graph',
                 'P' : True,
                 'A' : not preset['scratch'],
                 'R' : False if preset['db']=='px' else True,
@@ -71,7 +71,7 @@ for preset in [
                 config['lr'] = 3e-5
                 config['num_epochs'] = 30
             
-
+            
             # Run script
             exp_config = Configuration(config)
             SRC_PATH, TRAINING_CONFIG_LIST = exp_config.get_configuration()
diff --git a/gtx/src/model.py b/gtx/src/model.py
index 1d6c2b8..3cb062e 100644
--- a/gtx/src/model.py
+++ b/gtx/src/model.py
@@ -776,13 +776,13 @@ class GTXEncoder(nn.Module):
         # Using self.layer instead of self.l_layer to support loading BERT weights.
         self.layer = nn.ModuleList([GTXLayer(config) for _ in range(self.num_l_layers)])
         notifier.warning(f"This model has a {config.cross_att_type if 'cross_att_type' in vars(config).keys() else 'cross'} type of x_attention architecture.")
-        self.x_layers = nn.ModuleList([GTXXLayer(config) for _ in range(self.num_x_layers)])
-        if ("lit" in self.config.KnowMix) or ("abs" in self.config.KnowMix) or ("summary" in self.config.KnowMix) or ("adm" in self.config.KnowMix):
-            notifier.critical(f"Use Knowledge Mixup Layer on {config.KnowMix} nodes")
-            self.r_layers = nn.ModuleList([GTXKnowMixLayer(config) for _ in range(self.num_r_layers)])
-        else:
-            notifier.critical("Use Standard GAT Layer")
-            self.r_layers = nn.ModuleList([GTXLayer(config) for _ in range(self.num_r_layers)])            
+        # self.x_layers = nn.ModuleList([GTXXLayer(config) for _ in range(self.num_x_layers)])
+        # if ("lit" in self.config.KnowMix) or ("abs" in self.config.KnowMix) or ("summary" in self.config.KnowMix) or ("adm" in self.config.KnowMix):
+        #     notifier.critical(f"Use Knowledge Mixup Layer on {config.KnowMix} nodes")
+        #     self.r_layers = nn.ModuleList([GTXKnowMixLayer(config) for _ in range(self.num_r_layers)])
+        # else:
+        #     notifier.critical("Use Standard GAT Layer")
+        #     self.r_layers = nn.ModuleList([GTXLayer(config) for _ in range(self.num_r_layers)])            
         
         # Lang Encoder Architecture
         # LSTM for generation, BiLSTM for pretraining/other donwstream tasks
@@ -883,40 +883,40 @@ class GTXEncoder(nn.Module):
         else:
             extended_kg_ext_sum_attention_mask = None
 
-        for layer_module in self.r_layers:
-            if ("lit" in self.config.KnowMix) or ("abs" in self.config.KnowMix) or ("summary" in self.config.KnowMix) or ("adm" in self.config.KnowMix):
-                kg_outputs = layer_module(
-                    kg_feats,
-                    kg_attention_mask,
-                    contexts=kg_ext_input_ids,
-                    context_attention_masks=extended_kg_ext_attention_mask,
-                    summaries = kg_ext_sum_input_ids,
-                    summary_attention_masks = extended_kg_ext_sum_attention_mask,
-                    KnowMix_indices=kg_ext_attention_mask,
-                    output_attentions=output_attentions
-                )
-            else:
-                kg_outputs = layer_module(kg_feats, kg_attention_mask, output_attentions=output_attentions)
-            kg_feats = kg_outputs[0]
-            kg_hidden_states = kg_hidden_states + (kg_feats,)
-            if kg_attentions is not None:
-                kg_attentions = kg_attentions + (kg_outputs[1],)
-
-        # Run cross-modality layers
-        for layer_module in self.x_layers:
-            x_outputs = layer_module(
-                lang_feats,
-                lang_attention_mask,
-                kg_feats,
-                kg_padding_mask,
-                kg_padding_mask,
-                output_attentions=output_attentions,
-            )
-            lang_feats, kg_feats = x_outputs[:2]
-            kg_hidden_states = kg_hidden_states + (kg_feats,)
-            language_hidden_states = language_hidden_states + (lang_feats,)
-            if cross_encoder_attentions is not None:
-                cross_encoder_attentions = {k:cross_encoder_attentions[k] + (x_outputs[2][k],) for k in cross_encoder_attentions}
+        # for layer_module in self.r_layers:
+        #     if ("lit" in self.config.KnowMix) or ("abs" in self.config.KnowMix) or ("summary" in self.config.KnowMix) or ("adm" in self.config.KnowMix):
+        #         kg_outputs = layer_module(
+        #             kg_feats,
+        #             kg_attention_mask,
+        #             contexts=kg_ext_input_ids,
+        #             context_attention_masks=extended_kg_ext_attention_mask,
+        #             summaries = kg_ext_sum_input_ids,
+        #             summary_attention_masks = extended_kg_ext_sum_attention_mask,
+        #             KnowMix_indices=kg_ext_attention_mask,
+        #             output_attentions=output_attentions
+        #         )
+        #     else:
+        #         kg_outputs = layer_module(kg_feats, kg_attention_mask, output_attentions=output_attentions)
+        #     kg_feats = kg_outputs[0]
+        #     kg_hidden_states = kg_hidden_states + (kg_feats,)
+        #     if kg_attentions is not None:
+        #         kg_attentions = kg_attentions + (kg_outputs[1],)
+
+        # # Run cross-modality layers
+        # for layer_module in self.x_layers:
+        #     x_outputs = layer_module(
+        #         lang_feats,
+        #         lang_attention_mask,
+        #         kg_feats,
+        #         kg_padding_mask,
+        #         kg_padding_mask,
+        #         output_attentions=output_attentions,
+        #     )
+        #     lang_feats, kg_feats = x_outputs[:2]
+        #     kg_hidden_states = kg_hidden_states + (kg_feats,)
+        #     language_hidden_states = language_hidden_states + (lang_feats,)
+        #     if cross_encoder_attentions is not None:
+        #         cross_encoder_attentions = {k:cross_encoder_attentions[k] + (x_outputs[2][k],) for k in cross_encoder_attentions}
         kg_encoder_outputs = (
             kg_hidden_states,
             kg_attentions if output_attentions else None,
