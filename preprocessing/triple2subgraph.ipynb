{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▏                                                                 | 331362/18755503 [00:00<00:11, 1650791.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start preprocessing\n",
      "level:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 18755503/18755503 [00:10<00:00, 1848322.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15929096/18755503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                    | 78773/15929096 [00:00<00:20, 779935.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 15929096/15929096 [00:18<00:00, 841698.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/15929096\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "triples = [x.split() for x in open('train2id.txt').read().splitlines()[1:]]\n",
    "node2edge = {(h,t):r for h,t,r in triples}\n",
    "nodes = {x.split()[0]:x.split()[1] for x in open('entity2id.txt').read().splitlines()[1:]}\n",
    "edges = {x.split()[0]:x.split()[1] for x in open('relation2id.txt').read().splitlines()[1:]}\n",
    "\n",
    "# Initialize subgraph\n",
    "adm_node = list()\n",
    "for node in list(nodes.items()):\n",
    "    if 'hadm' in node[0]:\n",
    "        adm_node.append(node[1])\n",
    "subgraph_norel = [{node:list() for node in adm_node}]\n",
    "\n",
    "#subgraph_rel = dict(adm_node)\n",
    "#node_dict = list(subgraph_norel.keys())\n",
    "\n",
    "# Build subgraph\n",
    "print('start preprocessing')\n",
    "level = 0\n",
    "while len(triples)>0:\n",
    "    queue = list()\n",
    "    print('level:{}'.format(level))\n",
    "    for triple in tqdm(triples):\n",
    "        if triple[0] in subgraph_norel[level]:\n",
    "            subgraph_norel[level][triple[0]].append(triple[1])\n",
    "            flag = False\n",
    "        else:\n",
    "            flag = True\n",
    "        if flag:\n",
    "            queue.append(triple)\n",
    "    print('{}/{}'.format(len(queue),len(triples)))\n",
    "    new_head = list()\n",
    "    for heads in list(subgraph_norel[level].values()):\n",
    "        new_head+=heads\n",
    "    subgraph_norel.append({k:list() for k in new_head})\n",
    "    triples = queue\n",
    "    level += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_childs(subgraph, depth, heads):\n",
    "    temp_seq = list()\n",
    "    for head in heads:\n",
    "        temp_seq += subgraph[depth][head]\n",
    "    return temp_seq\n",
    "\n",
    "subs = list()\n",
    "max_len = 0\n",
    "for head in tqdm(list(subgraph_norel[0].keys())):\n",
    "    depth=0\n",
    "    seq = [head]\n",
    "    heads = [head]\n",
    "    while depth<2:\n",
    "        heads = get_childs(subgraph_norel,depth,heads)\n",
    "        seq += heads\n",
    "        depth+=1\n",
    "    subs.append([int(x) for x in seq])\n",
    "    if len(seq)>max_len:\n",
    "        max_len = len(seq)\n",
    "\n",
    "tensorized_subgraphs = torch.LongTensor([x+[-100]*(max_len-len(x)) for x in subs])\n",
    "print(max_len)\n",
    "print('Saving...')\n",
    "torch.save(tensorized_subgraphs,'subgraph_norel')\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 31969/31969 [00:33<00:00, 946.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16405\n",
      "Saving...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def get_childs_withrel(subgraph, depth, heads,node2edge):\n",
    "    temp_seq = list()\n",
    "    temp_heads = list()\n",
    "    for head in heads:\n",
    "        node_set = [(head,tail) for tail in subgraph[depth][head]]\n",
    "        for node_pair in node_set:\n",
    "            temp_seq += ['r'+node2edge[node_pair],node_pair[1]]\n",
    "        temp_heads += subgraph[depth][head]\n",
    "    return temp_seq, temp_heads\n",
    "\n",
    "subs = list()\n",
    "max_len = 0\n",
    "for head in tqdm(list(subgraph_norel[0].keys())):\n",
    "    depth=0\n",
    "    seq = [head]\n",
    "    heads = [head]\n",
    "    while depth<2:\n",
    "        seqs, heads = get_childs_withrel(subgraph_norel,depth,heads,node2edge)\n",
    "        seq += seqs\n",
    "        depth+=1\n",
    "    subs.append(list(map(lambda x: int(x) if 'r' not in x else -(int(x.split('r')[-1])+1),seq)))\n",
    "    if len(seq)>max_len:\n",
    "        max_len = len(seq)\n",
    "\n",
    "tensorized_subgraphs = torch.LongTensor([x+[-100]*(max_len-len(x)) for x in subs])\n",
    "print(max_len)\n",
    "print('Saving...')\n",
    "torch.save(tensorized_subgraphs,'subgraph_withrel')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['72', '93519', '206215', '242177', '334606']\n",
      "tensor([      7,      -4,       8,      -4,  283300,      -4,  575838,      -4,\n",
      "         719045,      -4,  645680,      -4,  989663,      -4,  426595,      -4,\n",
      "        1076656,      -4,  463680,      -4, 1233681,      -4,  908837,      -4,\n",
      "        1283846,      -4, 1290906,      -4, 1628720,      -4, 1629404,      -4,\n",
      "        1772376,      -4,  352772,      -4, 1809227,      -4,  533009,      -4,\n",
      "         498708,      -4, 1858488,      -4, 1902562,      -4, 1915416,      -4,\n",
      "        1955206,      -4, 2042356,      -4,  881922,      -4, 2094568,      -4,\n",
      "        2098564,      -4, 2099384,      -4,   80624,      -4, 2157778,      -4,\n",
      "        1888242,      -4, 1802277,      -4, 2302185,      -4, 2322619,      -4,\n",
      "        1523716,      -4, 1261659,      -4,  448803,      -4,  696941,      -4,\n",
      "        1189685,      -4,  927060,      -4, 1791294,      -4, 1649091,      -4,\n",
      "         260145,      -4,  245836,      -4, 2620781,      -4, 2118448,      -4,\n",
      "        2670715,      -4, 2638043,      -4, 1750725,      -4,  425937,      -4,\n",
      "        2496969,      -4,  665084,      -4,  544576,      -4, 2333432,      -4,\n",
      "        2188358,      -4, 1933096,      -4, 1270876,      -4, 2138930,      -4,\n",
      "         387321,      -4, 2310806,      -4,  959704,      -4, 1357463,      -4,\n",
      "        2843002,      -4,  528401,      -4, 1533121,      -4, 1743407,      -4,\n",
      "        1999589,      -4, 2520639,      -4, 1489543,      -4,  876316,      -4,\n",
      "        1448315,      -4, 1998580,      -4, 1037800,      -4, 2612638,      -4,\n",
      "         585652,      -4, 1778503,      -4, 1778677,      -4,  949199,      -4,\n",
      "        1484641,      -4, 1607883,      -4,  777305,      -4,  378480,      -4,\n",
      "        1693630,      -4, 1086148,      -4,  927842,      -4,  592749,      -4,\n",
      "        2839456,      -4, 1899081,      -4, 2567920,      -4,  115395,      -4,\n",
      "        1783426,      -4,  199385,      -4, 2890074,      -4, 1933364,      -4,\n",
      "         459735,      -4, 2612848,      -4,  449523,      -4,  797115,      -4,\n",
      "        2128924,      -4, 1489225,      -4, 1131656,      -4, 2481134,      -4,\n",
      "        2160938,      -4, 1905126,      -4, 2031265,      -4, 2643215,      -4,\n",
      "        2562387,      -4,  140164,      -4,  686231,      -4,  714317,      -4,\n",
      "          85218,      -4, 1555173,      -4, 2644210,      -4, 2162331,      -4,\n",
      "         722922,      -4, 2720538,      -4, 2690194,      -4, 1268119,      -4,\n",
      "        2801437,      -4, 1907865,      -4,   65839,      -4, 2799342,      -4,\n",
      "        2828012,      -4, 1895985,      -4, 2828461,      -4,  807116,      -4,\n",
      "         107257,      -4,   88471,      -4,  711476,      -4, 2430237,      -4,\n",
      "        2162685,      -4, 2669370,      -4, 1833045,      -4, 2772077,      -4,\n",
      "         812287,      -4,  636271,      -4, 2707172,      -4, 1629556,      -4,\n",
      "         601200,      -4, 2200425,      -4, 1343441,      -4, 1649172,      -4,\n",
      "        2138104,      -4, 1705777,      -4, 2653593,      -7,     197,      -6,\n",
      "           1763,      -5,     104,      -3,   39211,      -1,       1,      -1,\n",
      "              1,      -7,     197,      -5,     104,      -6,    1763,      -3,\n",
      "           1491,      -2,   80625,      -7,      46,      -3,    1231,      -1,\n",
      "              1,      -5,     778,      -6,     941,      -5,    2415,      -7,\n",
      "             46,      -1,       1,      -3,   13203,      -2,   80625,      -6,\n",
      "          17161,      -1,       1,      -2,   80625,      -7,      89,      -6,\n",
      "           7139,      -3,    1853,      -5,   37761,      -3,       6,      -2,\n",
      "          80625,      -5,     956,      -7,      58,      -6,     760,      -1,\n",
      "             56,      -1,       1,      -6,     104,      -6,     104,      -7,\n",
      "            197,      -3,      36,      -7,     197,      -1,       1,      -5,\n",
      "            104,      -3,      36,      -5,     104,      -5,     104,      -7,\n",
      "            197,      -6,    1763,      -1,       1,      -3,   98801,      -5,\n",
      "          10585,      -3,    2331,      -6,   47549,      -7,      89,      -1,\n",
      "              1,      -5,    3655,      -6,   21262,      -1,       1,      -3,\n",
      "           2205,      -2,   80625,      -7,      58,      -5,     104,      -3,\n",
      "          20248,      -1,       1,      -6,    1763,      -7,     197,      -5,\n",
      "            104,      -7,     197,      -3,  165909,      -6,    1763,      -1,\n",
      "              1,      -6,    1763,      -5,     104,      -3,   98801,      -7,\n",
      "            197,      -1,       1,      -5,     104,      -7,     197,      -3,\n",
      "          39211,      -1,       1,      -6,    1763,      -3,      36,      -1,\n",
      "              1,      -7,     197,      -6,     104,      -6,     104,      -5,\n",
      "            104,      -5,     104,      -1,       1,      -7,     197,      -3,\n",
      "             36,      -7,     197,      -5,     104,      -1,       1,      -3,\n",
      "          20248,      -6,    1763,      -6,   21262,      -3,    2205,      -2,\n",
      "          80625,      -7,      58,      -1,       1,      -5,    3655,      -5,\n",
      "            104,      -7,     197,      -3])\n"
     ]
    }
   ],
   "source": [
    "print(subgraph_norel[0]['71'][:5])\n",
    "print(tensorized_subgraphs[0,:500])\n",
    "#tensorized_subgraphs[3,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
